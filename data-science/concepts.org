* Errores comunes
- En realidad no hay problemas qué resolver
- Existían soluciones más simples
- No puedes medir el impacto de tu modelo
- No sabes si el problema ya ha sido resuelto
- El problema era imposible de resolver
* Preguntas clave
** ¿Qué beneficio piensas generar y para quién?
** ¿Qué funcionalidad te sería más útil para lograr ese objetivo?:
*** Aprendizaje supervisado
- Predecir una métrica
- Predecir una etiqueta
*** Aprendizaje no supervisado
- Agrupar elementos similares
- Optimizar un proceso con prueba y error
* Aterriza tu problema de aprendizaje supervisado
** ¿De qué tipo es el valor que quieres predecir?
- Variables contínuas (cualquier float, número real)
- Variables discretas (valores finitos)
** ¿Cuál es tu definición de éxito de una predicción?
- Puede ser precisión, el ricon
** ¿Con qué datos vas a hacer esta predicción?
** ¿La pregunta que estás tratando de resolver pertenece a alguna disciplina en particular?
** ¿Considerando tu intuición en la disciplina, crees que los datos te permitan predecir tu objetivo?
* Métodos destacados
#+begin_src python
 # MOSTRAR TIEMPO PARA UN COMANDO
 %timeit

 # MOSTRAR GRÁFICA EN LA MISMA LÍNEA
 %matplotlib inline

 # Help of a function
 help(aquí-va-el-nombre-de-la-función)

 data = pandas.read_csv(’path/to/data’) # data will be a pandas.DataFrame
 data.head # show 
 data.index # “primary key” of data
 data.columns # columns of data
 data.loc[idx, col] # idx [escalar or vector]: some index(es), col [escalar or vector]: some column(s)
 data[’someColumnName’]
 data.info # show the name and elements type of each data’s column
 data.dtype # show all the types, is a pandas.DataFrame.Series
 
 # Columnas de TEXTO: 
 # returning true only for the data’s columns with string elements:
 obj = (data.dtype == object)
 # columns name of data’s column with string elements
 obj_stringColumns = [c for c in obj.index if obj[c]]
 # Result
 data_obj = data[obj_stringColumns] # pandas.DataFrame

 # Columnas NUMÉRICAS
 # returning true only for the data’s columns with string elements:
 num = (data.dtype == float) | (data.dtype == int)
 # columns name of data’s column with string elements
 num_numericColumns = [c for c in num.index if num[c]]
 # Result
 data_num = data[num_numericColumns] # pandas.DataFrame

 # ESTADÍSTICAS de las columnas numéricas (Numeric columns ONLY)
 data_num.describe() # returns the count, mean, std, percentiles at 25% 50% 75% and max

 data_num[’someColumnName’].hist()

 # ESTADÍSTICAS de las columnas de texto

 # CREANDO MÁSCARAS
 mask = (data[’someColumnName’] > someValue) # example: mask = (movies[’budget’] > 1e9)
 # se genera un dataframe con las mismas columnas e index pero los elementos son solo valores true cuando se cumple la condición or false en el caso contrario
 
 data[mask] # extrae los elementos donde mask tiene el valor de true

 # Cargando otro CSV in data2
 data2 = pd.read_csv(’path/to/data2’) # pandas.DataFrame

 # Concatenando dataframes (EJEMPLO)
  # Concatenando una columna de strings (Object type) al dataframe de valores numéricos
 movies_num = pd.concat([movies_num, movies[’movie_title’]], axis=1)

 # Merge de dataframes
  # a 3° pandas.Dataframe = pd.merge(a 1° DataFrame, a 2° Dataframe, on='A 2° Dataframe’s column name’, how=’the left (a 1°) or the right (a 2°) Dataframe’)
  movies_v2 = pd.merge(data2, movies_num, on=’movie_title’, how=’left’)
  # con how='left’, movies_v2 queda definido con el pandas.DataFrame.index de data2
  # con how=right’, movies_v2 queda definido con el pandas.DataFrame.index de movies_num
  # por lo tanto se alterará el pandas.DataFrame.shape

  # Generar un dataframe con iguales nombres de columnas e index pero con elementos true para elementos no NaN y false para el caso contrario
  pandas.DataFrame.notnull()
  
  pandas.DataFrame.notnull().apply(some-function) # Apply ejecutará ’some-function’ sobre los elementos del DataFrame
  # EJEMPLO: si ’some-function’ = pd.Series.value_conts, en el caso anterior se contará cuántos true or false hay

  available = pandas.DataFrame.notnull().all(axis=1).value_counts()
  mask2 = available[’someColumnName’]
  movies_v2 = movies_v2[mask2]

  ( (movies_v2 != 0) & (movies_v2.notnull()) ).worldwide_gross.value_counts()

  from sklearn.preprocessing import Imputer
  imputer = Imputer(missing_values=np.nan, strategy=’mean’, axis=1)

  movies_v2.drop(’title’) # pandas.DataFrame.drop()

  values = imputer.fit_transform(movies_v2) 

  X = pd.DataFrame(values)
  X.columns = movies_v2.columns
  X.index = movies_v2.index
  X.head()
  X.to_csv(’some/path/to/save/X.csv’, index=False)

  # Scikit-learn es la librería más usada de Machine Learning tradicional Ver ranking de Github. La librería incluye funcionalidades de:

  #  Preprocesamiento de datos en  sklearn.preprocessing 
  #  Algoritmos de Machine Learning en sklearn.linear_model, sklearn.svm, sklearn.ensemble, y muchos más.
  #  Evaluación de modelos en sklearn.model_selection y sklearn.metrics

  X = pd.read(’path/to/X.csv’)
  Y = X[’worldwide_gross’]
  X = X.drop('worldwide_gross')

  X_test, Y_test, X_train, Y_train = train_test_split(X, Y)
  estimador (entrenado) = fit(Hiperparámetros, estimador (instanciado), X_train, Y_train)
  Y_predicted = estimador(entrenado).predict (X_test)
  theScore = score(Y_predicted, Y_test)

  # Comparar Y_test vs Y_predicted
  plt.hist(Y_test, Y_predicted)

  # Evaluando de forma más fina el error (residuals)
  residuals = Y_test - y_predicted
  plt.catter(Y_test, residuals) # [Error en absoluto - dólares?] mientras esta gráfica muestre puntos dispersos sin patrones, está bien
  
  ap_residuals = np.abs(residuale) / Y_test
  plt.scatter(Y_test, ap_residuals)  # [Error en porcentaje]

  lap_residuals = np.log(ap_residuals) # [Error en algoritmo] escala en magnitud, más que en porcentaje
  plt.scatter(Y_test, lap_residuals)

  plt.hist(lap_residuals, bins=100, normed=1, histtype=’step’, cumulative=True); # [Evolucion del error del error de las medias] => col. horizontal de valores menores a 0: % del error, col. vertical: % de datos

  # DISEÑO DE FEATURES
  # Métodos heurísticos:
  # - Features informativas
  # - Features independientes
  # - Cantidad de features controladas

  X = pd.read_csv(’some/path/to/file’)
  
  import seaborn as sns

  # Visualizar correlación features
  sns.heatmap(X.corr()) # La diagonal está abstante roja porque es es la misma en horiz. y vert. por las demás partes deberían estar en tonos claros mostrando así que las features están sanas (poca correlación)

  # Se necesita aumentar el número de dimensiones en forma exponensial para tener solo un poco de información de un hiercubo, por lo que es mejor mantener la menor cantidad de dimensiones posibles

#+end_src
